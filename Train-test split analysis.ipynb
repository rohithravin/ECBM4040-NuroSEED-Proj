{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1844b0",
   "metadata": {},
   "source": [
    "# Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d265d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from utils.preprocessing import process_seqs\n",
    "from model.train_model import train_siamese_model\n",
    "from model.models_cstm import get_embedding_model\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def test_split(seqs_path, y_path, depth):\n",
    "    \"\"\"\n",
    "    Helper function for generating cladistic train-test split analysis. The idea is to vary the depth,\n",
    "    keeping other variables consistent. \n",
    "    \"\"\"\n",
    "    # Load data from known y matrix\n",
    "    data = process_seqs(\n",
    "        seqs_path=seqs_path,\n",
    "        train_test_split='distance',\n",
    "        split_depth=depth,\n",
    "        test_size=0.2,\n",
    "        val_size=0.2,\n",
    "        load_y=y_path,\n",
    "        lim=1000,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Get input/output sizes\n",
    "    in_dim = data[0][0].shape[1]\n",
    "    out_dim = int(in_dim / 2)\n",
    "    \n",
    "    # Specifying model this way keeps hyperparameters consistent\n",
    "    model, score, history = train_siamese_model(\n",
    "        data,\n",
    "        embedding_model=get_embedding_model(in_dim=in_dim, out_dim=out_dim),\n",
    "        distance_metric='euclidean',\n",
    "        epochs=1,\n",
    "        batch_size=512\n",
    "    )\n",
    "    return model, score, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86198286",
   "metadata": {},
   "source": [
    "# PheS case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ab166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "phes_fasta_path = \"./data/phes/phes_na.fa\"\n",
    "phes_y_path = \"./data/phes/y.pkl\"\n",
    "history_path=\"./results/train_test/phes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2cfb390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPTH = 0: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.609 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.110 seconds\n",
      "\tShapes of data: (600, 1674), (200, 1674), (200, 1674)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 19:42:21.870138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-17 19:42:22.382457: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 84s 241ms/step - loss: 18075.9648 - val_loss: 8318.5488\n",
      "38/38 [==============================] - 5s 122ms/step - loss: 9410.5293\n",
      "\tSCORE: 9410.529296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 19:43:52.610151: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_0/assets\n",
      "DEPTH = 1: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.632 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.122 seconds\n",
      "\tShapes of data: (600, 1674), (200, 1674), (200, 1674)\n",
      "350/350 [==============================] - 86s 244ms/step - loss: 8014.6484 - val_loss: 7190.0791\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 8440.3975\n",
      "\tSCORE: 8440.3974609375\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_1/assets\n",
      "DEPTH = 2: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.701 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.198 seconds\n",
      "\tShapes of data: (599, 1674), (200, 1674), (201, 1674)\n",
      "349/349 [==============================] - 81s 233ms/step - loss: 6949.5557 - val_loss: 8175.0034\n",
      "38/38 [==============================] - 4s 98ms/step - loss: 9571.3457\n",
      "\tSCORE: 9571.345703125\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_2/assets\n",
      "DEPTH = 3: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.558 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.110 seconds\n",
      "\tShapes of data: (598, 1674), (202, 1674), (200, 1674)\n",
      "348/348 [==============================] - 84s 243ms/step - loss: 6801.5483 - val_loss: 7290.6235\n",
      "39/39 [==============================] - 4s 105ms/step - loss: 6927.5947\n",
      "\tSCORE: 6927.5947265625\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_3/assets\n",
      "DEPTH = 4: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.657 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.123 seconds\n",
      "\tShapes of data: (598, 1674), (201, 1674), (201, 1674)\n",
      "348/348 [==============================] - 98s 281ms/step - loss: 6693.4058 - val_loss: 8273.4287\n",
      "39/39 [==============================] - 4s 94ms/step - loss: 5038.0728\n",
      "\tSCORE: 5038.07275390625\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_4/assets\n",
      "DEPTH = 5: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.550 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.170 seconds\n",
      "\tShapes of data: (588, 1674), (209, 1674), (203, 1674)\n",
      "337/337 [==============================] - 79s 236ms/step - loss: 6618.8730 - val_loss: 8104.8384\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 4883.0483\n",
      "\tSCORE: 4883.04833984375\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_5/assets\n",
      "DEPTH = 6: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.519 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.061 seconds\n",
      "\tShapes of data: (593, 1674), (206, 1674), (201, 1674)\n",
      "342/342 [==============================] - 81s 237ms/step - loss: 6190.3589 - val_loss: 10699.4580\n",
      "41/41 [==============================] - 4s 94ms/step - loss: 8518.6768\n",
      "\tSCORE: 8518.6767578125\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_6/assets\n",
      "DEPTH = 7: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.558 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.091 seconds\n",
      "\tShapes of data: (527, 1674), (260, 1674), (213, 1674)\n",
      "270/270 [==============================] - 65s 241ms/step - loss: 7088.6958 - val_loss: 21139.7832\n",
      "65/65 [==============================] - 7s 107ms/step - loss: 8040.2891\n",
      "\tSCORE: 8040.2890625\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_7/assets\n",
      "DEPTH = 8: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.889 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.192 seconds\n",
      "\tShapes of data: (463, 1674), (298, 1674), (239, 1674)\n",
      "208/208 [==============================] - 55s 265ms/step - loss: 7447.2261 - val_loss: 30527.1562\n",
      "86/86 [==============================] - 11s 124ms/step - loss: 21483.8203\n",
      "\tSCORE: 21483.8203125\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_8/assets\n",
      "DEPTH = 9: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.649 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.094 seconds\n",
      "\tShapes of data: (435, 1674), (299, 1674), (266, 1674)\n",
      "184/184 [==============================] - 52s 282ms/step - loss: 8634.8506 - val_loss: 42677.3945\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 25772.4395\n",
      "\tSCORE: 25772.439453125\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_9/assets\n",
      "DEPTH = 10: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 0.633 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.059 seconds\n",
      "\tShapes of data: (449, 1674), (323, 1674), (228, 1674)\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 10526.8867 - val_loss: 16723.5078\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 19996.8691\n",
      "\tSCORE: 19996.869140625\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_10/assets\n",
      "DEPTH = 11: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 1.194 seconds\n",
      "\tShape of X: (1000, 1674)\n",
      "Loading distances from ./data/phes/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.149 seconds\n",
      "\tShapes of data: (133, 1674), (404, 1674), (463, 1674)\n",
      "17/17 [==============================] - 27s 2s/step - loss: 88678.3594 - val_loss: 40369.3164\n",
      "158/158 [==============================] - 18s 116ms/step - loss: 77212.4766\n",
      "\tSCORE: 77212.4765625\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/phes/model_11/assets\n"
     ]
    }
   ],
   "source": [
    "# max_depth = np.ceil(np.log2(0.2 * n_seqs))\n",
    "scores = pd.DataFrame(columns=[\"depth\", \"score\"])\n",
    "for depth in range(12):\n",
    "    # Running function\n",
    "    print(f\"DEPTH = {depth}:\", \"#\"*100)\n",
    "    model, score, history = test_split(phes_fasta_path, phes_y_path, depth)\n",
    "    print(f\"\\tSCORE: {score}\")\n",
    "    \n",
    "    # Saving\n",
    "    model.save(f\"{history_path}/model_{depth}\")\n",
    "    pd.DataFrame(history.history).to_pickle(f\"{history_path}/history_{depth}.pkl\")\n",
    "    scores = scores.append({\"depth\" : depth, \"score\" : score}, ignore_index=True)\n",
    "\n",
    "scores.to_pickle(f\"{history_path}/scores.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c23b89",
   "metadata": {},
   "source": [
    "# 16S rRNA case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f02278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_fasta_path = \"./data/16s/16s_na.fa\"\n",
    "rna_y_path = \"./data/16s/y.pkl\"\n",
    "history_path=\"./results/train_test/16s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fef2606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPTH = 0: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 1.050 seconds\n",
      "\tShape of X: (1000, 1803)\n",
      "Loading distances from ./data/16s/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.861 seconds\n",
      "\tShapes of data: (600, 1803), (200, 1803), (200, 1803)\n",
      "350/350 [==============================] - 111s 318ms/step - loss: 8504.9033 - val_loss: 10017.1250\n",
      "38/38 [==============================] - 6s 147ms/step - loss: 6233.1890\n",
      "\tSCORE: 6233.18896484375\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/16s/model_0/assets\n",
      "DEPTH = 1: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 1.069 seconds\n",
      "\tShape of X: (1000, 1803)\n",
      "Loading distances from ./data/16s/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 1.291 seconds\n",
      "\tShapes of data: (600, 1803), (200, 1803), (200, 1803)\n",
      "350/350 [==============================] - 115s 327ms/step - loss: 9069.3555 - val_loss: 9968.8125\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 5346.9683\n",
      "\tSCORE: 5346.96826171875\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/16s/model_1/assets\n",
      "DEPTH = 2: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 1.186 seconds\n",
      "\tShape of X: (1000, 1803)\n",
      "Loading distances from ./data/16s/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.648 seconds\n",
      "\tShapes of data: (598, 1803), (202, 1803), (200, 1803)\n",
      "348/348 [==============================] - 89s 256ms/step - loss: 9963.6641 - val_loss: 6432.5449\n",
      "39/39 [==============================] - 4s 109ms/step - loss: 7540.5889\n",
      "\tSCORE: 7540.5888671875\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/16s/model_2/assets\n",
      "DEPTH = 3: ####################################################################################################\n",
      "Reading inputs...\n",
      "\tDone in 1.038 seconds\n",
      "\tShape of X: (1000, 1803)\n",
      "Loading distances from ./data/16s/y.pkl\n",
      "Splitting X values...\n",
      "\tDone in 0.504 seconds\n",
      "\tShapes of data: (595, 1803), (203, 1803), (202, 1803)\n",
      "345/345 [==============================] - 94s 271ms/step - loss: 9955.9004 - val_loss: 8015.6353\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 9792.9541\n",
      "\tSCORE: 9792.9541015625\n",
      "INFO:tensorflow:Assets written to: ./results/train_test/16s/model_3/assets\n",
      "DEPTH = 4: ####################################################################################################\n",
      "Reading inputs...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/16s/16s_na.fa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pv/wpxck4ks01s92c9pgwg6q2_00000gp/T/ipykernel_22681/3459316809.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Running function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DEPTH = {depth}:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna_fasta_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrna_y_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\tSCORE: {score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pv/wpxck4ks01s92c9pgwg6q2_00000gp/T/ipykernel_22681/1006561792.py\u001b[0m in \u001b[0;36mtest_split\u001b[0;34m(seqs_path, y_path, depth)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     data = process_seqs(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mseqs_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseqs_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Columbia/year2/4040/ECBM4040-NuroSEED-Proj/utils/preprocessing.py\u001b[0m in \u001b[0;36mprocess_seqs\u001b[0;34m(seqs_path, tree_path, train_test_split, split_depth, test_size, val_size, lim, drop_nontree_seqs, n_threads, save_y, load_y, verbose)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading inputs...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasta_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mtock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Columbia/year2/4040/ECBM4040-NuroSEED-Proj/utils/preprocessing.py\u001b[0m in \u001b[0;36mfasta_to_numpy\u001b[0;34m(path, lim)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mseqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/16s/16s_na.fa'"
     ]
    }
   ],
   "source": [
    "# max_depth = np.ceil(np.log2(0.2 * n_seqs))\n",
    "scores = pd.DataFrame(columns=[\"depth\", \"score\"])\n",
    "for depth in range(12):\n",
    "    # Running function\n",
    "    print(f\"DEPTH = {depth}:\", \"#\"*100)\n",
    "    model, score, history = test_split(rna_fasta_path, rna_y_path, depth)\n",
    "    print(f\"\\tSCORE: {score}\")\n",
    "    \n",
    "    # Saving\n",
    "    model.save(f\"{history_path}/model_{depth}\")\n",
    "    pd.DataFrame(history.history).to_pickle(f\"{history_path}/history_{depth}.pkl\")\n",
    "    scores = scores.append({\"depth\" : depth, \"score\" : score}, ignore_index=True)\n",
    "\n",
    "scores.to_pickle(f\"{history_path}/scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4227c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
